---
title: "Statistics for Data Science"
author: "Laurie Baker"
date: "03/12/2019 - 05/12/2019"
output: 
    ioslides_presentation:
        incremental: true
        widescreen: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



```{python Importing packages setting plot defaults, echo = FALSE}
import numpy as np # linear algebra
import pandas as pd # data processing
import matplotlib.pyplot as plt # data plotting
import seaborn as sns # data visualisation and plotting
import statsmodels.api as sm # statistical modelling package
import statsmodels.formula.api as smf # statistical modelling package with R-like formulas
import scipy.stats as stats
import math

sns.set(color_codes=True)

from statsmodels.genmod.generalized_linear_model import GLM # importing packages to run GLM
from statsmodels.genmod import families # importing families for exponential families
from scipy.stats import binom # to illustrate the binomial distribution.
from sklearn import datasets, linear_model # fetching iris dataset and linear model functions
from sklearn.metrics import mean_squared_error, r2_score

# Seaborn plot default configurations
sns.set_style("darkgrid")

# set the custom size for my graphs
#sns.set(rc={'figure.figsize':(8.7,6.27)})


```

```{python Function to read in the data, echo = FALSE}


# Define sklearn_to_df function to convert from sklearn to a pandas dataframes

def sklearn_to_df(sklearn_dataset):
    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)
    df['target'] = pd.Categorical.from_codes(sklearn_dataset.target, sklearn_dataset.target_names)
    return df

```



```{python Importing and converting iris data to a pandas dataframe, echo = FALSE}

# import and convert format of iris data from sklearn
df_iris = sklearn_to_df(datasets.load_iris())

```
  
  


```{r Call reticulate library to include python code chunks, echo=FALSE}
library(reticulate)
matplotlib <- import("matplotlib", convert = TRUE) 
matplotlib$use("Agg")
use_python("/Library/Frameworks/Python.framework/Versions/3.7/bin/python3")
```

## Overview

Day 1

>  * Exploratory Data Analysis: 11.10-12:30
>  * Linear Models: 13:15-16:30
 
Day 2

>  * Generalized Linear Models Part I: 9:30-12:30
>  * Generalized Linear Models Part II: 13:30-16:30

Day 3

>  * Intro to Bayesian Analysis Part I: 9:30-12:30
>  * Intro to Bayesian Analysis Part 2: 13:30-15:00

## Point System

Small prize at the end of the week for the person with the most points

>  * 1 pt per spelling mistake
>  * 3 pts per mistake in the code
>  * 5 pts per mistake fixed in the code

To be tallied at the end of each day. 

## Road Map of the Modelling Process

![Serra Rio do Rastro. Source: Rosanetur https://flic.kr/p/QV7ttk.](pictures/serra_rio.jpg)

## Road Map of the Modelling Process

1. Identify the data science question you wish to explore
    - At a general, conceptual level:  "Are bed nets an effective intervention against malaria" 
    - At a specific level: "What is the percentage reduction in malaria cases between area A where bed nets are being used and area B where bed nets are not being used".

2. Explore the data

3. Choose the model

4. Fit parameters

5. Estimate confidence intervals/test hypotheses/select models

<div class="notes">

1. **Identify the data science question you wish to explore.** Try to identify your question at both a general, conceptual level "Are bed nets an effective intervention against malaria" and at a specific level "what is the percentage reduction in malaria cases between area A where bed nets are being used and area B where bed nets are not being used".

2. **Explore the data.** Explore the variation and covariation in the data. Identify patterns through plotting which can be explored further using formal statistical testing. 

3. **Choose the model:** choose the mathematical description of the pattern you are trying to describe. The *deterministic* part is the average, or expected pattern in the absence of any kind of randomness or measurement error. The *stochastic* part of the model is the variation around the expected pattern. Typically you describe the stochastic model by specifying a reasonable *probability distribution* for the variation. 

4. **Fit parameters:** once you have defined your model, you can estimate both the deterministic parameters (slope, intercept, ...) and stochastic parameters (the variance or parameters controlling the variance). The parameters are effectively the answers to your questions from **1**. 

5. **Estimate confidence intervals/test hypotheses/select models:** measurements of uncertainty are necessary to contextualise your best-fit parameters. By quantifying the uncertainty in the fit of a model, you can estimate confidence limits for the parameters. You can then test your hypothesis statistially and practically, can we tell the difference statistically between the effect of bed nets to control malaria? Are these differences large enough to make bed nets an effective intervention strategy?

</div>

## Exploratory Data Analysis

- Hypothesis generation
- Data exploration
- Formal statistical testing

## Iris data


![Source: Suruchi Fialoke, October 13, 2016, Classification of Iris Varieties.](pictures/iris_classification.png){width=650px}

## Tidy Data

Tabular data is a set of values, where each `value` is placed in its own “cell”, each `variable` in its own column, and each `observation` in its own row.

  - A `variable` is a quantity, quality, or property that you can measure.

  - A `value` is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.

  - An `observation` is a set of measurements made under similar conditions. An observation will contain several values, each associated with a different variable.

## Iris data as a pandas dataframe

![](pictures/tidy_iris_example.png){width=650px}

Who can spot the:

> - variable?
> - value?
> - observation?

## Getting to know your data

To get started, let's explore the following questions for our dataset. 

 1. What is the structure of the data?

 2. What type of variation occurs within my variables?

 3. What type of covariation occurs between my variables? 
 
## Data Structure and Data Summaries

   - `Continuous variable`: a variable that can take on an unlimited number of values between the lowest and highest points of measurements.
   
        - e.g. speed, distance, height
        
        
  - `Categorical variable` can take **one** of a limited subset of values. 
  
        - e.g. gender, marriage status, county.
        
        
  - A `Categorical variable` is
  
        - `nominal` if they have no order (e.g. 'Ghana' and 'Uruguay')
        
        - `ordinal` if there is an order associated with them (e.g. 'low', 'medium', and 'high')
  
  
<div class="notes">
 * Introducing the slide: Variables can come in two forms. As either a continuous or a categorical variable. 
  * In python, categorical variables are usually stored as character strings or integers (e.g. 'M' and 'F' for male and female). 

</div>


## Your Turn

Run the lines of code to answer the questions below

1. What are the dimensions of the dataframe?

2. What are the first and last values of sepal.length?

3. Which variables are float64s or categories?

4. Using the data summary, what is the minimum and maximum sepal length?

5. What are the names of the columns?

## 1. What are the dimensions of the dataframe?

```{python Dataframe Dimensions,  echo = T}
print(df_iris.shape)

```

## 2a. What are the first values of sepal.length?


```{python Head and Tail of Data, echo = T}

df_iris.head(5)

```

## 2b. What are the last values of sepal.length?


```{python Tail of Data, echo = T}

df_iris.tail(5)
```

## 3. Which variables are float64s or categories?


```{python Data Structure, echo = T}
df_iris.info()
```

## 4. Using the data summary, what is the minimum and maximum sepal length?


```{python Data Summary, echo = T}

df_iris.describe()

```


## 5. What are the names of the columns?

```{python Column Names, echo = T}

# Let's simplify the column names and make them more meaningful

df_iris = df_iris.rename(columns = {'sepal length (cm)': 'sepal_length', 
      'sepal width (cm)': 'sepal_width', 'petal length (cm)': 'petal_length', 
      'petal width (cm)': 'petal_width','target': 'species'})

# What are the names of the columns?

df_iris.columns

```


## Variation and Covariation

**Variation** and **covariation** help us understand the spread of the data and identify potential relationships in the data.

- `Variation`: is the tendency of values of a variable to change from measurement to measurement.  
    - `measurement error` you may measure the same thing twice and get slightly different values.
    - `natural variation` in a population or sample (e.g. height)

- `Covariation`: tendency of values of a variable to change with the values of another variable.


<div class="notes">
Introduce the slide: Now we know more about the structure of our data we can explore the variation and covariation in the variables. Knowing the variation and covariation between variables can help us to understand the spread of the data and potential relationships in the data that may give insight into modelling.  

Lead in to the next slide: Visualisation is a great initial tool to explore these relationships further. How you visualise this variation depends on whether the variable is categorical or continuous?
</div>



## Visualising a Categorical Variable

```{python Bar plot of species, echo = T, out.width = "500px", out.height = "400px"}

species_counts = sns.countplot(x= "species", data = df_iris)
species_counts

```


<div class="notes">
Introduce the slide: How you visualise your variables depends on if the variable is `categorical` or `continuous`.

Remember from before that, a categorical variable can take on one of a limited, usually fixed number of possible values, assigning each value to a particular group or nominal category. 
        * e.g. sex, race, density: (high, medium, low)


Lead in to the next slide: Visualisation is a great initial tool to explore these relationships further.
</div>

## Visualising a continuous variable

```{python Distribution plot of Petal Length, echo = T, out.width = "500px", out.height = "350px", echo = TRUE, eval = FALSE}
petal_length_all_distplot = sns.distplot(df_iris['petal_length'], 
              hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})
petal_length_all_distplot.set(xlabel='Petal_length', ylabel='Density')
petal_length_all_distplot;
```

## Visualising a continuous variable

```{python Distribution plot of Petal Length 2, echo = T, out.width = "500px", out.height = "350px", echo = FALSE, eval = TRUE}
petal_length_all_distplot = sns.distplot(df_iris['petal_length'], 
              hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})
petal_length_all_distplot.set(xlabel='Petal_length', ylabel='Density')
petal_length_all_distplot;
```


Something interesting seems to be happening with the data

<div class="notes">
A `continuous variable` can take any of an infinite set of ordered values (e.g. numbers and date times). We can inspect the spread of the data using a density plot or box plot. 


If we look at the distribution of petal length, something interesting seems to be happening. It appears that the distribution is *bimodal* meaning that there are two modes, in this case two maxima, in the data. 
</div>

## Visualising a continuous variable

```{python Distribution plot of each species, echo = T, eval = F}
df_setosa = df_iris[df_iris.species == 'setosa']
petal_length_species = sns.distplot(df_setosa[['petal_length']], label = 'setosa', 
              hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})

df_virginica = df_iris[df_iris.species == 'virginica']
petal_length_species = sns.distplot(df_virginica[['petal_length']], label = 'virginica', 
              hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})

df_versicolor = df_iris[df_iris.species == 'versicolor']
petal_length_species = sns.distplot(df_versicolor[['petal_length']], label = 'versicolor', 
              hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})
petal_length_species.set(xlabel='Petal Length', ylabel='Density x 10')

petal_length_species;
```

## Visualising a continuous variable

```{python Distribution plot of each species plotted}
df_setosa = df_iris[df_iris.species == 'setosa']
petal_length_species = sns.distplot(df_setosa[['petal_length']], label = 'setosa', 
              hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})

df_virginica = df_iris[df_iris.species == 'virginica']
petal_length_species = sns.distplot(df_virginica[['petal_length']], label = 'virginica', 
              hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})

df_versicolor = df_iris[df_iris.species == 'versicolor']
petal_length_species = sns.distplot(df_versicolor[['petal_length']], label = 'versicolor', 
              hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3})
petal_length_species.set(xlabel='Petal Length', ylabel='Density x 10')

petal_length_species;
```


## Continuous and a categorical variable

```{python Boxplot of petal width, echo = T, out.width = "500px", out.height = "400px"}
petal_width_boxplot = sns.boxplot(data = df_iris, y = 'petal_width', x = 'species')
petal_width_boxplot

```


<div class="notes">
* A box plot gives us a visual representation of the distribution of numeric data using quartiles. It can be a good way to see how the data is spread and to identify potential outliers. 
    * The box plot shows the median (second quartile) in the middle of the plot.
    * The first and third quartile represent the interquartile range (25\% to 75\%). 
    * The minimum and maximum are defined as the (Q1 - 1.5 x IQ) and (Q3 + 1.5 x IQ).
</div>

## Continuous and a categorical variable


```{python Violin plot of sepal length by species, echo = T, out.width = "500px", out.height = "400px"}

sepal_length_violin = sns.violinplot(data = df_iris, y = "sepal_length", x = 'species')
sepal_length_violin
```


<div class="notes">
Violin plots are similar to box plots, but they also show the probability density of the data at different values, usually smoothed by a kernel density estimator. 
</div>
## Visualising two continuous variables

Plotting two continuous variables, we can see how they change in relation to eachother. 

- **positive relationship** as one variable increases the other variable increases

- **negative relationship** as one variable increases the other decreases

- **no relationship** no discernable pattern of change in one variable with the other.

- **non-linear relationship** we may also be able to pick out other patterns, e.g. *polynomials*. 

## Visualising two continuous variables

```{python Scatterplot of petal length and sepal width, echo = T, out.width = "450px", out.height = "350px"}

iris_scatter_petal_length_sepal_width = sns.scatterplot(data = df_iris, x = 'petal_length',
      y = 'sepal_width', hue = 'species')
iris_scatter_petal_length_sepal_width

```

## Your Turn

**Exercises**

1. **Make a box plot or a violin plot of sepal width by species.** How does this box plot/violin plot compare to the earlier box plot/violin plot we made of petal width and sepal length?

2. **Make a scatterplot to visualise the relationship between petal length and sepal length coloured by species.** What patterns can you pick out from the data?


## Exercise: Sepal width by species


```{python Violin plot of sepal width by species, echo = T, out.width = "500px", out.height = "400px"}

sepal_width_violin = sns.violinplot(data = df_iris, y = 'sepal_width', x = 'species')
sepal_width_violin
```


<div class="notes">
Sepal width by species 
</div>

## Exercise: Petal length by sepal length

```{python Scatterplot of petal length and sepal length, echo = T, out.width = "450px", out.height = "350px"}

iris_length_scatter = sns.scatterplot(data = df_iris, x = 'petal_length', 
          y = 'sepal_length', hue = 'species')
iris_length_scatter

```


<div class="notes">
Petal length by sepal length coloured by species. 
</div>

## Your Turn

> 3. Pairplots can be a quick and useful way to summarise your dataset quickly and to inspect the relationships simultaneously. What does this code do?

```{python Pairplot of the data, echo = TRUE, eval = FALSE}
iris_all_pairplot = sns.pairplot(data = df_iris, hue="species", diag_kind="kde")
iris_all_pairplot


```


# Model Basics

## Hypothesis generation vs. hypothesis confirmation

Focus of modelling is on **inference** or confirming a hypothesis is true.

1. Each observation can either be used for exploration or confirmation, not both.
2. You can use an observation for exploration as many times as you want.
3. Can only use an observation once for confirmation. 
 
 
<div class="notes">
**Hypothesis generation vs. hypothesis confirmation**

  * Traditionally, one of the focuses of modelling is on **inference**, or confirming that a hypothesis is true. To do it correctly you need to know two things:
  
    1. Each observation can either be used for exploration or confirmation, not both. 
    2. You can use an observation as many times as you like for exploration, but you can only use it once for confirmation. As soon as you use an observation twice, you've switched from confirmation to exploration. 
    
* Note, that in order to confirm a hypothesis, you must use data independent of the data used to generate the hypothesis.
</div>


## Model basics

A goal of models is to partition data into **patterns** and **residuals**.

1. **Family of models:**
    - Express precise, but generic pattern you wish to capture. 
    - E.g., a straight line $y = ax + b$ or quadratic curve $y = ax^2 + bx + c$. 

2. **Fitted model**
    - The **model family** is expressed as an equation.
    - In model fitting, the different parameters are able to take on different values to **adjust** the shape of the **fitted line** to the data.
    * N.B. The fitted model is just the closest model from a family of models. 
 

<div class="notes">

* Ideally your model will 
    * capture **signals** (i.e. patterns)
    * and ignore **noise** (i.e. random variation).
 
A goal of models is to partition data into **patterns** and **residuals**.

There are two key parts to a model:

1. Family of models:
  * define a family of models that express precise, but generic pattern you wish to capture. For example, a straight line $y = ax + b$ or quadratic curve $y = ax^2 + bx + c$. Where $x$ and $y$ are known variables from your data, and $a$, $b$, and $c$ are parameters that can vary to capture different patterns. 

2. Fitted model
    * After you've chosen your model family, the next step is to generate a fitted model from that family that is closest to your data. 
    * the **model family** is expressed as an equation, where the different parameters are able to take on different values to adjust the shape of the fitted line to the data.

N.B. The fitted model is just the closest model from a family of models. 

</div>

## Family of models and fitted models


<img src="pictures/clothesline.jpg" height="300px" />
<img src="pictures/tailor_fit.jpg" height="300px" />

<div class="notes">
If we use clothes as an analogy, the family of models is like an assortment of garments you could choose to 'clothe' the data in. Just as some clothes will be more suitable than others depending on what you wish to do (e.g. nice dress to a wedding), the same is true for models. The type of model will depend on the type of data you have and what you wish to do with your analysis. 

Model fitting is similar to getting a garment tailored. Just as you might make alterations to improve the fit of a garment, you will adapt the chosen model to get a better fit to the data. 

</div>


## Response and Explanatory variables

 * **Response variable**: the measured variable you are trying to explain
      * `Dependent`, `target` (machine learning) 
 * **Explanatory variables**: measured variables that we use to try to explain the response variable. 
      * `Independent`, `features` (machine learning)

<div class="notes">
In the field of data science you will see a number of terms used to refer to the same things. Here, we will use `response variable` to refer to the measured variable you are trying to explain. We will use `explanatory variables` to refer to the measured variables that we use to try to explain the response variable. Other terms that you may come across for these concepts include:
 * **response variable**: `dependent`, `target` (machine learning) 
 * **explanatory variables**: `independent`, `features` (machine learning)

</div>

## Linear Models

Linear models take the mathematical form:

$y = ax + b$

  * $y$ is the response variable 
  * $a$ is the slope 
  * $x$ is an explanatory variable
  * $b$ is the intercept.

<div class="notes">
Linear regression is one of the most important and widely used regression techniques. Its main advantage is its simple structure and ease of interpreting results.

</div>

## Selling Irises

A data scientist sees a market $ for selling irises to nostalgic ex-statistics undergraduates.

![Source: Suruchi Fialoke, October 13, 2016, Classification of Iris Varieties.](pictures/iris_classification.png){width=650px}

Irises with the widest petals sell best (largest `petal_width`).

- What is the relationship between petal width and petal length? How do these relationships vary with species? 

<div class="notes">
A data scientist is setting up a side business of breeding irises to sell to other data scientists who have rosy nostalgic memories of studying the iris dataset when they were budding data scientists. They are interested in the relationship between petal width and petal length as they find that the irises with the widest petals sell better. 


</div>


## Petal length and petal width

```{python Scatterplot of petal length and petal width, echo = TRUE, out.width = "450px", out.height = "350px"}

iris_scatter_petal_length_width = sns.scatterplot(data = df_iris, x = 'petal_length', 
    y = 'petal_width', hue = 'species')
iris_scatter_petal_length_width

```


<div class="notes">
Let's start by taking a closer look at the iris data to explore the relationship between petal length and petal width.

From the plot it looks like there is a positive relationship between petal length and petal width. Let's use a model to capture the pattern and make it more explicit. In this case, the relationship looks linear so we can use the form: $y = ax + b$. We are interested in how petal width changes with petal length. We can make a guess at what the parameters for a and b might be. It looks like petal width increases more slowly than petal length, maybe at 0.3 cm for every 1 cm in petal length. 


</div>

##Plotting the relationship

* $y = 0.3x + 0.1$

```{python Scatterplot with 1 potential line to describe relationship, echo = TRUE, out.width = "500px", out.height = "400px"}

iris_scatter_petal_length_width = sns.scatterplot(data = df_iris, x = 'petal_length', 
    y = 'petal_width', hue = 'species')

x = np.arange(7)
a = 0.3
b = 0.1
y = a*x + b


iris_scatter_petal_length_width = sns.regplot(x=x, y=y, marker="+")
iris_scatter_petal_length_width

```


<div class="notes">
Not bad, but maybe we could do a bit better.
</div>

## Plotting the relationship

```{python Scatterplot with two potential lines with different values for the slope and intercept 1, echo = TRUE, eval = FALSE}

iris_scatter_petal_length_width = sns.scatterplot(data = df_iris, x = 'petal_length', 
    y = 'petal_width', hue = 'species')

x = np.arange(7)
a = 0.37
a1 = 0.35
b = -0.2
b1 = -0.3
y = a*x + b
y1 = a1*x + b

iris_scatter_petal_length_width = sns.regplot(x=x, y=y, marker="+")
iris_scatter_petal_length_width = sns.regplot(x=x, y=y1, marker="+", 
    line_kws={"color": "red"})
iris_scatter_petal_length_width

```


## Plotting the relationship

```{python Scatterplot with two potential lines with different values for the slope and intercept 2, eval = TRUE, out.width = "600px", out.height = "500px"}

iris_scatter_petal_length_width = sns.scatterplot(data = df_iris, 
    x = 'petal_length', y = 'petal_width', 
    hue = 'species')

x = np.arange(7)
a = 0.37
a1 = 0.35
b = -0.2
b1 = -0.3
y = a*x + b
y1 = a1*x + b

iris_scatter_petal_length_width = sns.regplot(x=x, y=y, 
      marker="+")
iris_scatter_petal_length_width = sns.regplot(x=x, y=y1,
      marker="+", line_kws={"color": "red"})
iris_scatter_petal_length_width

```

<div class="notes">
The two lines have slightly different parameters. It is difficult to tell by eye which line fits the data better. We could do this ourselves, by measuring the `residuals`, the distance from the data (actual response) to the line (predicted response), for each model, and comparing them. But this can be time-consuming, especially if our goal is to find the best model which could involve looking at more than just two models! 

</div>

<div class="notes">

Luckily python has built-in functions that will explore all the possibilities to find the 'best' line. In linear regression, one of the ways to define the 'best' line is by finding the line that minimizes the sum of squared residuals (aka sum of squares). Calculating the sum of squared residuals involves taking the residual distances, squaring them, and summing them. This approach is also called Ordinary Least Squares (OLS), after which the OLS function in python takes its name. 

</div>

## Model Construction

> - We use the `statsmodels function api`
    > - Formula specified as: `formula = y ~ x`
    > - N.B. smf.ols automatically includes the intercept. 


```{python Model 1 specification and model fit, echo = T}

model1 = smf.ols(formula = 'petal_width ~ petal_length', data = df_iris)

results_mod1 = model1.fit()

```


<div class="notes">

Here we use the `statsmodels function api` to construct our models. This allows us to specify an intuitive model formula for our analyses where `formula = y ~ x`. In this case `y` is our response variable, the tilde $~$ means "depends on" `x`, which represents an explanatory variable (i.e. the variable we are using to try to explain the variation in y). 

Let's take a look at what this looks like in practice. In this case we're interested in explaining the variation in `petal_width` using the explantory variable, `petal_length`.

Note that the smf.ols function automatically includes the intercept in the model, so we don't have to specify one.

</div>

## Fitted Model 1 Output

```{python model 1 fit results}

print(results_mod1.summary())

```


<div class="notes">

The summary gives us a range of diagnostic information about the model we've fitted, split into three tables. Here's a quick guide on what is included:

**Top Table - model fit info.**

  * **R-squared/Adj. R-squared** - The proportion of the variance in the response variable ('petal_width') explained by the model. The Adj. R-squared takes into account the number of variables in the model.
  * **No. of Observations** (i.e. measurements of 'petal_width') and  **Df** degrees of freedom (No. of Observations - (1 + No. of variables in the model)).
  * **General info** - date and time that model was run, type of model etc.
  * **Model Fit info** - inc. **F-statistic**, **AIC** and **BIC**, **Log-Likelihood**. They are not meaningful on their own, but allow you to compare different models to assess the best one. 
    
**Middle Table - an important table!**

  * **coef** = coefficient estimates for the intercept and explanatory variables.
  * **std err** = standard errors (i.e. estimate of the uncertainty) of the coefficient estimates.
  * **t** = t-statistic for the t-test comparing whether the coefficient is different to 0.
  * **P>|t|** = p-value for the t statistics, giving significance of coefficient.
  * **[0.025 0.975]** = 95% confidence interval around the coefficient estimate.
    
**Bottom table - Diagnostics**

  * **Jarque-Bera**, **Omnibus**: test normality of residuals.
  * **Cond, No.**: Condition Number, test for multicollinearity.
  * **Durbin-Watson**: test for autocorrelation.


As you can see, there is a lot of information in the summary. Let's focus on a few relevant values from the model to focus on.


</div>

## Fitted Model 1 Output

![Model Results.](pictures/linear_model_petal_width_vs_length_annotated.png){width=700px}

## Extracting coefficients from the model output

We can get these specific parameters directly from the `model` object.

```{python Extracting parameters directly from the model 1 object, echo = T}

print("Intercept = ",results_mod1.params['Intercept'])
print("(Petal length) coef. = ", results_mod1.params['petal_length'])
print("R^2 = ", results_mod1.rsquared_adj)


```

<div class="notes">
This is a useful way to pull out information to further analyse or include in reports. We can pull out these coefficients to plot our line of best fit. 
</div>

## Constructing the line of best fit

```{python Scatterplot of line of best fit compared to two different slope and intercept to describe relationship between petal width and petal length 1, echo = TRUE, eval = FALSE}

iris_scatter = sns.scatterplot(data = df_iris, x = 'petal_length', 
    y = 'petal_width', hue = 'species')

x = np.arange(7)
a = 0.37; a1 = 0.35

b = -0.2; b1 = -0.3

y = a*x + b; y1 = a1*x + b1
y2 = results_mod1.params['petal_length']*x + results_mod1.params['Intercept']

iris_scatter = sns.regplot(x = x, y = y, marker="+")
iris_scatter = sns.regplot(x = x, y = y1, marker="+", 
      line_kws = {"color": "red"})
iris_scatter = sns.regplot(x = x, y = y2, marker = "+", 
      line_kws = {"color": "blue"})
iris_scatter

```

## Constructing the line of best fit

```{python Scatterplot of line of best fit compared to two different slope and intercept to describe relationship between petal width and petal length 2, echo = FALSE, eval = TRUE}

iris_scatter = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')

x = np.arange(7)
a = 0.37
a1 = 0.35

b = -0.2
b1 = -0.3

y = a*x + b
y1 = a1*x + b1
y2 = results_mod1.params['petal_length']*x + results_mod1.params['Intercept']

iris_scatter = sns.regplot(x = x, y = y, marker="+")
iris_scatter = sns.regplot(x = x, y = y1, marker="+", line_kws = {"color": "red"})
iris_scatter = sns.regplot(x = x, y = y2, marker = "+", line_kws = {"color": "blue"})
iris_scatter

```

## Constructing the line of best fit using regplot

```{python Model 1 scatterplot and line of best fit 1, echo = TRUE, eval = F}

iris_best_fit = sns.regplot(x = 'petal_length', y = 'petal_width', 
      ci = 95, data = df_iris)
iris_best_fit
```

<div class="notes">
We can do this plot by hand (as above) or directly from our model. 
</div>


## Constructing the line of best fit using regplot

```{python Model 1 scatterplot and line of best fit 2, out.width = "500px", out.height = "400px", echo = F}

iris_best_fit = sns.regplot(x = 'petal_length', y = 'petal_width', 
      ci = 95, data = df_iris)
iris_best_fit
```

<div class="notes">
We can do this plot by hand (as above) or directly from our model. 
</div>

## Residuals

 * `Residuals` represent the left over variation in the response variable not explained by the model.
      * Want to see an 'amorphous' cloud
* Patterns in the residuals may indicate
    * A missing variable
    * The variation in our response variable is not normally distributed.

<div class="notes">
We can then inspect the residuals in the model. `Residuals` represent the left over variation in the response variable not explained by the model. A pattern in the residuals may indicate that we are missing a variable or that our assumption of normality is incorrect. When we are looking at the residuals, we want them to form an 'amorphous cloud', i.e. a cloud shape with no patterns. 
</div>

## Residuals for Model 1


```{python Residual plot for Model 1, echo = TRUE, out.width = "500px", out.height = "400px"}
df_iris_resid = sns.residplot(y = 'petal_width', x = 'petal_length', data = df_iris)
df_iris_resid

```


<div class="notes">
It looks like there might be some patterns left in the data that are unexplained. We can see that as `petal_width` increases the variability and range of residual values also increase.
</div>

## Checking for Normality of Residuals


```{python, echo = F, out.width = "500px", out.height = "400px"}
mu = 0; variance = 1; sigma = math.sqrt(variance)

x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)
plt.plot(x, stats.norm.pdf(x, mu, sigma))
plt.xlabel('Value')
plt.ylabel('Density')
plt.show()

```

<div class="notes">

A key assumption of linear models is that the residuals are normally distributed. 

This is different from the response variable needs to be normally distributed.

What this means is that the residuals (i.e. the left over variation) are evenly spread and most are only a small distance. 

What you'll notice in the plot above is that it is symmetrical with most values falling close to 0.
</div>

## QQplot for checking Normality

```{python qqplot for Model 1, echo = T, out.width = "400px", out.height = "300px"}
resid = results_mod1.resid
# Use statsmodels qqplot to graph residuals
f, ax = plt.subplots(figsize=(7,7))
sm.graphics.qqplot(resid, line='45', fit=True, ax=ax);
```


<div class="notes">

A common plot used to inspect model residuals is a qqplot. The qqplot compares the residuals to a theoretical normal distribution. If the residuals come from a normal distribution we would expect the blue dots to line up with the red line.


The plot doesn't look too bad. The residuals mostly match the red line, but we can see that the tails of the qqplot are a little skewed, particularly to the right. This may mean that there is still some structure in the variation in `petal_width` that is not accounted for by `petal_length`.  We can see whether including species in the model helps explain some of the remaining variation in the model. 
</div>

## Model 2 with petal length and species

> * Explaining the variation in `petal_width` using `petal_length` and `C(species)`

```{python Model 2 specification and model fit 1, echo = T, eval = F}

model2 = smf.ols(formula = 'petal_width ~ petal_length + C(species)', data = df_iris)

results_mod2 = model2.fit()

print(results_mod2.summary())
```

<div class="notes">

Now we are constructing our model to explain the variation in `petal_width` using the variables for `petal_length` and `species`. In this case, because species is a categorical variable we can specify it using `C(species)`.

</div>

## Model 2 with petal length and species

```{python Model 2 specification and model fit 2, echo = F, eval = T, out.width = "500px", out.height = "400px"}

model2 = smf.ols(formula = 'petal_width ~ petal_length + C(species)', data = df_iris)

results_mod2 = model2.fit()

print(results_mod2.summary())
```

<div class="notes">

There are a few key things to pick out from the table above. First, we have an increase in the adjusted R^2, which is now 0.944, meaning we've explained 94.4 \% of the variation in petal_length. We also have several variables now:
 * `Intercept`
 * `C(species)[T.versicolor]`
 * `C(species)[T.virginica]`
 * `petal_length`
 
 
But remember that in our `df_iris` dataset there are three species of iris: setosa, versicolor, and virginica. Categorical variables always contribute to the intercept in a linear model. When fitting the model, the model function uses the first level of the categorical variable, in this case `setosa`, as the baseline `Intercept`. The coefficients estimated for `C(species)[T.versicolor]` and `C(species)[T.virginica]` are estimated in relation to that. 

</div>


## Residuals of Model 2


```{python Residuals for Model 2, echo = F, out.width = "500px", out.height = "400px"}
resid2 = results_mod2.resid
fitted2 = results_mod2.fittedvalues

resid2_plot = sns.scatterplot(x = fitted2, y = resid2)
resid2_plot.set(xlabel='Fitted', ylabel='Residuals')
resid2_plot;

```

## QQPlot of Model 2

```{python qqplot for Model 2, echo = F, out.width = "500px", out.height = "400px"}

# Use statsmodels qqplot to graph errors
f, ax = plt.subplots(figsize=(7,7))

sm.graphics.qqplot(resid2, line='45', fit=True, ax=ax);
```


<div class="notes">


Let's see what the residuals look like for our new model.

Now our residuals are slightly skewed to the left. Is there something more we might be missing from the model? So far we've allowed the intercept in our model to vary by species. Let's try letting our slope change also with species. By allowing our slope to vary by species we are exploring the hypothesis that **how** `petal_width` **changes** with `petal_length` varies by species. 
</div>

## Model 3 petal length * species interaction code

  > * Interactions are specified using the `*` between two variables. 

```{python Model 3 specification and resulting model fit code, echo = T, eval = F}

model3 = smf.ols(formula = 'petal_width ~ petal_length*C(species)', data = df_iris)

results_mod3 = model3.fit()

print(results_mod3.summary())
```

<div class="notes">

To do this in the model, we need to use an interaction term. Interactions are included using the multiplication symbol $*$ between two variables.

</div>

## Model 3 petal length * species interaction output

```{python Model 3 specification and resulting model fit output, echo = F, eval = T, out.width = "500px", out.height = "400px"}

model3 = smf.ols(formula = 'petal_width ~ petal_length*C(species)', data = df_iris)

results_mod3 = model3.fit()

print(results_mod3.summary())
```

<div class="notes">

If we look at the results, we can see that the slope for `petal_length` also uses setosa (the species name that is missing) as a baseline.

We can plot the model fit using our new coefficients. This time, both the slope and intercept will vary. 

</div>

## Line of best fit for Model 3 code slope

```{python Scatterplot and line of best fit for Model 3 code, echo = T, eval = F}

iris_scatter_species = sns.scatterplot(data = df_iris, x = 'petal_length', 
y = 'petal_width', hue = 'species')

x = np.arange(7)

a_setosa = results_mod3.params['petal_length']

a_virginica = results_mod3.params['petal_length:C(species)[T.virginica]'] + results_mod3.params['petal_length']

a_versicolor = results_mod3.params['petal_length:C(species)[T.versicolor]'] + results_mod3.params['petal_length']

b_setosa = results_mod3.params['Intercept']

b_virginica = results_mod3.params['C(species)[T.virginica]'] + results_mod3.params['Intercept']

b_versicolor = results_mod3.params['C(species)[T.versicolor]'] + results_mod3.params['Intercept']
```

## Line of best fit for Model 3 code intercept and plot

```{python Scatterplot and line of best fit for Model 3 code 2, echo = T, eval = F}

y_setosa = a_setosa*x + b_setosa
y_virginica = a_virginica*x + b_virginica
y_versicolor = a_versicolor*x + b_versicolor

iris_scatter_species = sns.regplot(x = x, y = y_setosa, marker= "+", 
      line_kws = {"color": "blue"})
      
iris_scatter_species = sns.regplot(x = x, y = y_virginica, marker = "+", 
      line_kws = {"color": "green"})
      
iris_scatter_species = sns.regplot(x = x, y = y_versicolor, marker = "+", 
      line_kws = {"color": "orange"})

iris_scatter_species

```


## Line of best fit for Model 3 plot

```{python Scatterplot and line of best fit for Model 3 plot, echo = F, eval = T, out.width = "500px", out.height = "400px"}

iris_scatter_species = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')

x = np.arange(7)
a_setosa = results_mod3.params['petal_length']
a_virginica = results_mod3.params['petal_length:C(species)[T.virginica]'] + results_mod3.params['petal_length']
a_versicolor = results_mod3.params['petal_length:C(species)[T.versicolor]'] + results_mod3.params['petal_length']

b_setosa = results_mod3.params['Intercept']
b_virginica = results_mod3.params['C(species)[T.virginica]'] + results_mod3.params['Intercept']
b_versicolor = results_mod3.params['C(species)[T.versicolor]'] + results_mod3.params['Intercept']


y_setosa = a_setosa*x + b_setosa
y_virginica = a_virginica*x + b_virginica
y_versicolor = a_versicolor*x + b_versicolor

iris_scatter_species = sns.regplot(x = x, y = y_setosa, marker= "+", line_kws = {"color": "blue"})
iris_scatter_species = sns.regplot(x = x, y = y_virginica, marker = "+", line_kws = {"color": "green"})
iris_scatter_species = sns.regplot(x = x, y = y_versicolor, marker = "+", line_kws = {"color": "orange"})

iris_scatter_species

```

## Residuals for Model 3


```{python Residuals Model 3, out.width = "500px", out.height = "400px"}

resid3 = results_mod3.resid
fitted3 = results_mod3.fittedvalues


resid3_plot = sns.scatterplot(x = fitted3, y = resid3)
resid3_plot;

```

## QQPlot for Model 3

```{python qqplot for Model 3, out.width = "400px", out.height = "300px"}

# Use statsmodels qqplot to graph errors
# make a figure and an axis
f, ax = plt.subplots(figsize=(7,7))
# call the qqplot graph from statsmodels 'graphics' module.
# fits against the normal distribution as standard.

sm.graphics.qqplot(resid3, line='45', fit=True, ax=ax);

```

## Model Comparison

* How do we decide which model is better?

* The main metrics we will discuss in this course are:

  1. `Adjusted R^2`
  2. `AIC`
  3. `BIC`

* First, we will discuss `parsimony` and `Occam's Razor`

<div class="notes">

So how can we decide which model is better? There are a few metrics we can compare between the model that can be found in the top table. The three main ones we will discuss in this course are the `Adjusted R^2`, `AIC`, and `BIC`. Before getting to these concepts, let's discuss the concept of `parsimony` and `Occam's Razor`.

</div>

## Occam's razor: law of parsimony

* `Parsimony` (aka `Occam's razor`): 
    * Argument to choose simpler model over complex ones.
* **Model selection:** 
    * Complex model must not just be better, but a specified amount better than a simpler model. 

* **Practical considerations:**

  * Simple theories are easier to test than complex ones
  * Simple models often do a better job at predicting
  * Simple models require fewer parameters
  


  
<div class="notes">
`Parsimony` (aka `Occam's razor`) is a general argument for choosing simpler models even though we know the world is complex. Occam's razor says that when presented with competing hypotheses that make the same predictions, we should select the solution with the fewest assumptions. This is to say that all other things being equal, we should prefer a simpler model to a more complex one, especially when the data don't tell a clear story. 

Model selection approaches often go beyond parsimony to say that a more complex model must not be just better than, but a specified amount better than, a simpler model.

**Practical Considerations**

There is also a practical element to parsimony; simple theories are easier to test than complex ones. Similarly, simple models often do a better job at predicting. Because a simpler model requires fewer parameters it is also less expensive in terms of time or money to collect the data for it. 

</div>

## Occam's razor: law of parsimony


"With four parameters I can fit an elephant, and with five I can make him wiggle his trunk" ~ John Von Neumann


```{python, echo = FALSE, out.width = "400px", out.height = "300px"}
#Author: Piotr A. Zolnierczuk (zolnierczukp at ornl dot gov)

#Based on a paper by:
#Drawing an elephant with four complex parameters
#Jurgen Mayer, Khaled Khairy, and Jonathon Howard,
#Am. J. Phys. 78, 648 (2010), DOI:10.1119/1.3254017


import numpy as np
import pylab

# elephant parameters
p1, p2, p3, p4 = (50 - 30j, 18 +  8j, 12 - 10j, -14 - 60j )
p5 = 40 + 20j # eyepiece

def fourier(t, C):
    f = np.zeros(t.shape)
    A, B = C.real, C.imag
    for k in range(len(C)):
        f = f + A[k]*np.cos(k*t) + B[k]*np.sin(k*t)
    return f

def elephant(t, p1, p2, p3, p4, p5):
    npar = 6
    Cx = np.zeros((npar,), dtype='complex')
    Cy = np.zeros((npar,), dtype='complex')

    Cx[1] = p1.real*1j
    Cx[2] = p2.real*1j
    Cx[3] = p3.real
    Cx[5] = p4.real

    Cy[1] = p4.imag + p1.imag*1j
    Cy[2] = p2.imag*1j
    Cy[3] = p3.imag*1j

    x = np.append(fourier(t,Cx), [-p5.imag])
    y = np.append(fourier(t,Cy), [p5.imag])

    return x,y

x, y = elephant(np.linspace(0,2*np.pi,1000), p1, p2, p3, p4, p5)
pylab.plot(y,-x,'.')
pylab.show()
```

<div class="notes">

We need to draw the line somewhere: 

As we add more parameters to a model, we necessarily get an increasingly accurate fit to the particular data we have observed (the bias of our predictions decreases), but our precision for predicting future observations decreases as well (the varaince of our predictions increases). 

One way to think about it is that data contain a fixed amount of information; as we estimate more and more parameters we spread the data thinner and thinner. Eventually the gain in accuracy from having more details in the model is outweighed by the loss in precision from estimating the effect of each of those details more poorly.

</div>

## Model Comparison: Adjusted $R^2$

**Adjusted R^2**

R-squared is a goodness-of-fit measure for linear regression models. 


$\frac{\text{Variance explained by the model}}{ \text{Total variance}}$

It indicates the percentage of the variance in the response variable explained by the explanatory variables. 

<div class="notes">
It indicates the percentage of the variance in the response variable explained by the explanatory variables. It is calculated by:
</div>

## Model Comparison: Likelihood

> - The `likelihood` is the probability of the observed outcome (i.e. the data) given a particular choice of parameters. 

> - Maximum likeilhood: used to find the set of parameters **that make the observed data most likely to have occurred**. 


![Maximum likelihood. Source: Ashan Priyadarshana. https://medium.com/quick-code/maximum-likelihood-estimation-for-regression-65f9c99f815d](pictures/likelihood_example.png){width=450px}


<div class="notes">

The `likelihood` is the probability of the observed outcome (i.e. the data) given a particular choice of parameters. For a particular statistical model, maximum likelihood finds the set of parameters *that makes the observed data most likely to have occurred*. That is, we find the set of parameters that makes the likelihood as large as possible.

The diagram above shows what is happening when you are calculating the maximum likelihood. Here, we have a line of best fit, with the estimated values of the response variable $\hat y_{1...n}$ (red dots). The actual values of the response variable (our data), are reperesented by the black dots. The residuals are indicated by the $\epsilon$. These residual is the distance between the actual value of the response variable and the estimated value of the response variable. 

When we are calculating the maximum likelihood, we are looking for the parameters that maximise the likelihood of the data. The horizontal arrows trace up to the normal distribution which represents the fit. The closer to the peak of the distribution the data falls the "more likely" the data is given the parameters. 

For mathematical convience, we often work with the logarithm of the likelihood (the *log-likelihood*) instead of the likelihood. However, the parameters that give the maximum log-likelihood also give the maximum likelihood. 

</div>

## Model Comparison: Information Criteria

Information criteria are based on the expected distance between a particular model and the "true" model. 

* All information-theoretic methods involve finding the model that minimizes some criterion that is the sum of a term based on the likelihood and a *penalty term*.
    * often twice the negative log-likelihood is used.
    * penalty term varies for different information criteria. 

* Selecting models based on **information criteria** allows for the comparison of all candidate models at once, provided they are fit to the same data. 

<div class="notes">
**Information criteria** are based on the expected distance between a particular model and the "true" model. All information-theoretic methods reduce to finding the model that minimizes some criterion that is the sum of a term based on the likelihood (usually twice the negative log-likelihood) and a *penalty term* which is different for different information criteria. 

Selecting models based on information criteria allows for the comparison of all candidate models at once, provided they are fit to the same data. If there are missing values in certain variables and not others, the model will exclude these data when fitting by default, so you need to be careful that you are not comparing models which have been fit to different datasets. 

</div>

## AIC

The `Akaike Information Criterion`, or AIC, is the most widespread information criterion, and is defined as

$\text{AIC} = -2L + 2k$

- $L$ is the log-likelihood
- $k$ is the number of parameters in the model. 

- Small values represent better overall fits
- Adding a parameter with a negligible improvement in fit penalizes the AIC by 2 log-likelihood units.

## Some rough guidance for AIC

- Lower values of AIC indicated a better fit to the data regardless of whether they are positive or negative.

    - If you have two models with AIC: -213.09, and -289.12. The model with AIC -289.12 is better.
- AIC comparisons are only valid for models that are fit to the same response data (i.e. same y)

- For AIC, the rule of thumb people generally follow is that improvements of greater than 2 mean we can select the more complicated model.

## BIC
- The *Bayesian* information criterion (BIC) is the second most common.
- It uses a penalty term of $(log n)k$. 
- The BIC is more conservative than the AIC
    - insists on a greater improvement in fit to accept a more complex model.

## Approaches to model selection

- Models with multiple parameters and possible interactions between variable lead to a large number of models to try. 

- Two simple approaches to model selection include:

    - **forward selection** (add parameters one at a time to the simplest model)
    - **backward selection** (subtract parameters from the most complex model). 

## Approaches to model selection

- Too large a set of possibilities -> can arrive at different best models depending on if you use forward or backward selection.
- Algorithms that do a combo of forward and backward exist. 
- Want to be careful that model selection does not become **data-dredging**
- You should use:
    - Common sense and domain knowledge to identify most important comparisons
    - Plot the best candidate fits. Try to understand why different models fit the data approximatedly equally well. 


## Your Turn

1. Let's compare the models we ran using Adjusted R^2 and AIC. Using the notes above, discuss in groups which model you think is best and why?

**Adjusted R^2**
```{python Model Comparison: Comparing Adjusted R2}

#\n will put the results on the next line!

print("Adjusted R^2 Model 1 = ", results_mod1.rsquared_adj, "\nAdjusted R^2 Model 2 = ", results_mod2.rsquared_adj
, "\nAdjusted R^2 Model 3 = ", results_mod3.rsquared_adj)

```

**AIC**
```{python Model Comparision: Comparing AIC}

print("AIC Model 1 = ", results_mod1.aic, "\nAIC Model 2 = ", results_mod2.aic, "\nAIC Model 3 = ", results_mod3.aic)

```

2. Take a look at the main parameters of Model 2 and Model 3 from the model summary tables. Do they seem to vary much between the models?

## Your Turn

Make a new hypothesis from the iris data and take it through the modelling process.